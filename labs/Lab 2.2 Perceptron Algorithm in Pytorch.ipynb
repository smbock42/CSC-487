{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2.2: Perceptron Algorithm in PyTorch\n",
    "\n",
    "In this lab you will again implement the perceptron algorithm, but this time using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is very similar to NumPy in its basic functionality.  In PyTorch arrays are called tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(6)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(3,5).float()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A note on broadcasting:* You may have noticed in the previous lab that NumPy is particular about the sizes of the arrays in operations; PyTorch is the same way.\n",
    "\n",
    "For example, if `A` has shape `(10,5)` and `b` has shape `(10,)`, then we can't compute `A*b`.  It wants the *last* dimensions to match, not the first ones.  So you would need to do either `A.T*b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(10,5))\n",
    "b = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operands could not be broadcast together with shapes (10,5) (10,) \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    A*b\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53849326,  0.61794924,  0.25724827,  2.15560456,  0.65239875,\n",
       "         0.1881677 , -0.28086119, -0.36333908, -1.39255057, -0.77861819],\n",
       "       [ 0.40925365, -1.23791575,  0.08091155,  0.87416227, -1.47180364,\n",
       "        -0.91677052,  1.20006053, -0.70775214, -0.39988387,  0.19216515],\n",
       "       [-0.3016241 , -1.83171793, -0.79491266,  1.18114598,  0.1918409 ,\n",
       "        -0.18141798,  0.45490127, -0.87588322, -0.13709627,  0.9047354 ],\n",
       "       [ 2.5698935 ,  1.141673  ,  1.27170678, -0.13059384,  0.58410113,\n",
       "        -1.94559903,  0.6486021 , -0.62424314, -1.09347829,  1.75402836],\n",
       "       [ 1.29259891, -0.37273317, -0.39181144,  0.99370578,  2.74927729,\n",
       "         0.21047045, -0.4912661 , -1.02389111,  0.25735736,  0.99920915]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to introduce an extra dimension of size one to $b$.  However, note that this produces the transposed result from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53849326,  0.40925365, -0.3016241 ,  2.5698935 ,  1.29259891],\n",
       "       [ 0.61794924, -1.23791575, -1.83171793,  1.141673  , -0.37273317],\n",
       "       [ 0.25724827,  0.08091155, -0.79491266,  1.27170678, -0.39181144],\n",
       "       [ 2.15560456,  0.87416227,  1.18114598, -0.13059384,  0.99370578],\n",
       "       [ 0.65239875, -1.47180364,  0.1918409 ,  0.58410113,  2.74927729],\n",
       "       [ 0.1881677 , -0.91677052, -0.18141798, -1.94559903,  0.21047045],\n",
       "       [-0.28086119,  1.20006053,  0.45490127,  0.6486021 , -0.4912661 ],\n",
       "       [-0.36333908, -0.70775214, -0.87588322, -0.62424314, -1.02389111],\n",
       "       [-1.39255057, -0.39988387, -0.13709627, -1.09347829,  0.25735736],\n",
       "       [-0.77861819,  0.19216515,  0.9047354 ,  1.75402836,  0.99920915]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53849326,  0.40925365, -0.3016241 ,  2.5698935 ,  1.29259891],\n",
       "       [ 0.61794924, -1.23791575, -1.83171793,  1.141673  , -0.37273317],\n",
       "       [ 0.25724827,  0.08091155, -0.79491266,  1.27170678, -0.39181144],\n",
       "       [ 2.15560456,  0.87416227,  1.18114598, -0.13059384,  0.99370578],\n",
       "       [ 0.65239875, -1.47180364,  0.1918409 ,  0.58410113,  2.74927729],\n",
       "       [ 0.1881677 , -0.91677052, -0.18141798, -1.94559903,  0.21047045],\n",
       "       [-0.28086119,  1.20006053,  0.45490127,  0.6486021 , -0.4912661 ],\n",
       "       [-0.36333908, -0.70775214, -0.87588322, -0.62424314, -1.02389111],\n",
       "       [-1.39255057, -0.39988387, -0.13709627, -1.09347829,  0.25735736],\n",
       "       [-0.77861819,  0.19216515,  0.9047354 ,  1.75402836,  0.99920915]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*np.expand_dims(b,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, carefully check the sizes of all arrays in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loading and format the Palmer penguins dataset for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_penguins()\n",
    "\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# tricky code to randomly shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# select only two specices\n",
    "df = df[(df['species']=='Adelie')|(df['species']=='Chinstrap')]\n",
    "\n",
    "# get two features\n",
    "X = df[['flipper_length_mm','bill_length_mm']].values\n",
    "\n",
    "# convert speces labels to -1 and 1\n",
    "y = df['species'].map({'Adelie':-1,'Chinstrap':1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
    "\n",
    "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X -= np.mean(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our `X` and `y` arrays to torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.0794e+00,  1.2195e+01],\n",
       "        [ 3.0794e+00, -5.6047e+00],\n",
       "        [ 6.0794e+00, -2.0467e-01],\n",
       "        [ 5.0794e+00,  3.7953e+00],\n",
       "        [ 1.8079e+01,  9.9953e+00],\n",
       "        [ 1.0079e+01,  8.1953e+00],\n",
       "        [ 4.0794e+00, -1.7047e+00],\n",
       "        [ 7.0794e+00,  6.0953e+00],\n",
       "        [ 5.0794e+00,  1.0695e+01],\n",
       "        [-1.0921e+01,  3.9533e-01],\n",
       "        [ 1.0794e+00,  4.5953e+00],\n",
       "        [ 5.0794e+00,  1.9533e-01],\n",
       "        [-6.9206e+00, -3.8047e+00],\n",
       "        [ 4.0794e+00, -2.8047e+00],\n",
       "        [-4.9206e+00, -7.5047e+00],\n",
       "        [-1.9206e+00, -4.2047e+00],\n",
       "        [ 1.8079e+01,  2.0953e+00],\n",
       "        [ 7.0794e+00, -3.4047e+00],\n",
       "        [ 9.0794e+00, -5.0467e-01],\n",
       "        [-1.9206e+00,  3.8953e+00],\n",
       "        [-1.9206e+00, -8.5047e+00],\n",
       "        [ 5.0794e+00,  9.2953e+00],\n",
       "        [-5.9206e+00, -2.4047e+00],\n",
       "        [-5.9206e+00, -2.4047e+00],\n",
       "        [ 1.0079e+01, -6.3047e+00],\n",
       "        [-9.2056e-01,  2.9533e-01],\n",
       "        [ 6.0794e+00,  7.7953e+00],\n",
       "        [-4.9206e+00, -1.1047e+00],\n",
       "        [ 7.0794e+00, -1.4047e+00],\n",
       "        [ 3.0794e+00, -6.5047e+00],\n",
       "        [ 9.0794e+00,  9.9953e+00],\n",
       "        [-6.9206e+00, -6.3047e+00],\n",
       "        [-9.2056e-01, -3.2047e+00],\n",
       "        [ 1.0794e+00, -1.4047e+00],\n",
       "        [ 1.0794e+00,  3.6953e+00],\n",
       "        [ 7.9439e-02, -9.0467e-01],\n",
       "        [ 9.0794e+00,  8.4953e+00],\n",
       "        [-4.9206e+00,  9.4953e+00],\n",
       "        [ 9.0794e+00,  8.7953e+00],\n",
       "        [ 2.0079e+01,  6.9953e+00],\n",
       "        [ 1.0794e+00, -1.8047e+00],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [-8.9206e+00, -4.3047e+00],\n",
       "        [-4.9206e+00,  4.9533e-01],\n",
       "        [-9.2056e-01, -2.4047e+00],\n",
       "        [-1.9206e+00, -3.1047e+00],\n",
       "        [ 1.6079e+01, -1.2047e+00],\n",
       "        [ 1.3079e+01,  1.0795e+01],\n",
       "        [ 1.8079e+01,  6.9953e+00],\n",
       "        [-9.2056e-01, -3.4047e+00],\n",
       "        [ 1.5079e+01,  1.3795e+01],\n",
       "        [ 3.0794e+00,  7.1953e+00],\n",
       "        [-3.9206e+00, -9.0467e-01],\n",
       "        [ 1.3079e+01, -9.0467e-01],\n",
       "        [-1.7921e+01, -4.2047e+00],\n",
       "        [-6.9206e+00, -5.0047e+00],\n",
       "        [-7.9206e+00, -5.6047e+00],\n",
       "        [-9.2056e-01,  3.1953e+00],\n",
       "        [ 7.9439e-02,  4.8953e+00],\n",
       "        [ 1.4079e+01,  9.8953e+00],\n",
       "        [ 7.9439e-02,  4.4953e+00],\n",
       "        [-3.9206e+00, -9.9047e+00],\n",
       "        [ 3.0794e+00, -6.0047e+00],\n",
       "        [-9.2056e-01, -6.4047e+00],\n",
       "        [ 8.0794e+00, -4.6729e-03],\n",
       "        [ 1.3079e+01,  1.1495e+01],\n",
       "        [ 1.0794e+00,  9.2953e+00],\n",
       "        [-4.9206e+00,  4.1953e+00],\n",
       "        [ 4.0794e+00,  7.9953e+00],\n",
       "        [ 7.0794e+00,  5.4953e+00],\n",
       "        [-1.9206e+00, -2.8047e+00],\n",
       "        [ 3.0794e+00,  9.5327e-02],\n",
       "        [-1.9206e+00, -6.5047e+00],\n",
       "        [-2.9206e+00, -6.3047e+00],\n",
       "        [ 6.0794e+00, -3.9047e+00],\n",
       "        [-8.9206e+00, -1.4047e+00],\n",
       "        [-7.9206e+00, -1.1047e+00],\n",
       "        [-9.2056e-01,  6.4953e+00],\n",
       "        [-1.9921e+01, -4.1047e+00],\n",
       "        [ 3.0794e+00,  5.5953e+00],\n",
       "        [ 1.0079e+01, -6.0467e-01],\n",
       "        [-1.9206e+00, -5.7047e+00],\n",
       "        [-7.9206e+00, -2.2047e+00],\n",
       "        [-1.9206e+00, -6.0047e+00],\n",
       "        [ 6.0794e+00,  3.1953e+00],\n",
       "        [-5.9206e+00, -2.5047e+00],\n",
       "        [ 4.0794e+00,  8.8953e+00],\n",
       "        [ 9.0794e+00,  9.3953e+00],\n",
       "        [ 1.0794e+00, -2.3047e+00],\n",
       "        [-1.9206e+00, -2.4047e+00],\n",
       "        [ 2.0794e+00,  3.9953e+00],\n",
       "        [-4.9206e+00,  1.1953e+00],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [-1.9206e+00, -2.7047e+00],\n",
       "        [ 1.0794e+00,  7.5953e+00],\n",
       "        [ 1.0079e+01,  1.4953e+00],\n",
       "        [ 4.0794e+00,  6.9533e-01],\n",
       "        [-9.2056e-01, -3.0047e+00],\n",
       "        [ 6.0794e+00, -4.3047e+00],\n",
       "        [ 4.0794e+00, -2.4047e+00],\n",
       "        [-2.9206e+00, -7.4047e+00],\n",
       "        [ 4.0794e+00,  8.9533e-01],\n",
       "        [ 6.0794e+00, -7.4047e+00],\n",
       "        [-1.3921e+01, -4.8047e+00],\n",
       "        [-2.9206e+00,  4.7953e+00],\n",
       "        [ 6.0794e+00,  8.1953e+00],\n",
       "        [ 3.0794e+00,  3.9953e+00],\n",
       "        [ 1.1079e+01,  7.2953e+00],\n",
       "        [ 4.0794e+00,  3.4953e+00],\n",
       "        [-1.9206e+00,  4.3953e+00],\n",
       "        [-1.0921e+01, -4.4047e+00],\n",
       "        [ 1.0794e+00,  8.5953e+00],\n",
       "        [ 1.8079e+01,  8.7953e+00],\n",
       "        [-1.3921e+01, -8.9047e+00],\n",
       "        [-1.9206e+00, -7.0047e+00],\n",
       "        [-1.9206e+00, -3.8047e+00],\n",
       "        [-1.9206e+00, -3.2047e+00],\n",
       "        [ 1.0794e+00, -6.9047e+00],\n",
       "        [-3.9206e+00, -2.5047e+00],\n",
       "        [ 5.0794e+00,  4.9533e-01],\n",
       "        [-4.9206e+00, -3.9047e+00],\n",
       "        [ 7.9439e-02,  1.1953e+00],\n",
       "        [-6.9206e+00, -4.4047e+00],\n",
       "        [-6.9206e+00, -3.0047e+00],\n",
       "        [-9.9206e+00, -9.0467e-01],\n",
       "        [-1.5921e+01, -1.8047e+00],\n",
       "        [-7.9206e+00, -4.8047e+00],\n",
       "        [ 3.0794e+00, -3.3047e+00],\n",
       "        [ 4.0794e+00,  8.8953e+00],\n",
       "        [-1.9206e+00, -2.3047e+00],\n",
       "        [-6.9206e+00, -5.4047e+00],\n",
       "        [ 7.9439e-02, -4.0467e-01],\n",
       "        [-1.9206e+00,  8.0953e+00],\n",
       "        [ 7.0794e+00, -4.7047e+00],\n",
       "        [-1.9206e+00, -3.9047e+00],\n",
       "        [ 2.0794e+00, -7.0467e-01],\n",
       "        [-3.9206e+00, -1.9047e+00],\n",
       "        [ 2.0794e+00,  9.6953e+00],\n",
       "        [ 7.9439e-02, -7.0047e+00],\n",
       "        [ 7.0794e+00, -4.5047e+00],\n",
       "        [-1.0921e+01, -5.5047e+00],\n",
       "        [-4.9206e+00, -6.7047e+00],\n",
       "        [-1.0921e+01,  1.5995e+01],\n",
       "        [ 3.0794e+00,  7.6953e+00],\n",
       "        [-9.9206e+00, -9.0467e-01],\n",
       "        [-1.3921e+01, -2.5047e+00],\n",
       "        [-6.9206e+00, -8.0047e+00],\n",
       "        [-1.1921e+01, -3.2047e+00],\n",
       "        [ 1.0794e+00, -4.1047e+00],\n",
       "        [ 3.0794e+00,  3.6953e+00],\n",
       "        [-6.9206e+00, -5.0047e+00],\n",
       "        [ 7.9439e-02, -4.7047e+00],\n",
       "        [-9.2056e-01,  3.5953e+00],\n",
       "        [ 3.0794e+00, -5.0467e-01],\n",
       "        [ 1.1079e+01,  8.6953e+00],\n",
       "        [ 5.0794e+00,  9.9953e+00],\n",
       "        [ 8.0794e+00,  8.4953e+00],\n",
       "        [-4.9206e+00,  4.9533e-01],\n",
       "        [ 2.0794e+00, -4.4047e+00],\n",
       "        [-1.0921e+01, -2.9047e+00],\n",
       "        [-4.9206e+00, -1.4047e+00],\n",
       "        [ 3.0794e+00, -1.2047e+00],\n",
       "        [ 8.0794e+00,  7.4953e+00],\n",
       "        [ 3.0794e+00, -2.8047e+00],\n",
       "        [-1.3921e+01,  4.0953e+00],\n",
       "        [ 5.0794e+00,  1.0195e+01],\n",
       "        [-9.2056e-01, -6.0467e-01],\n",
       "        [ 3.0794e+00,  4.6953e+00],\n",
       "        [-9.2056e-01, -4.7047e+00],\n",
       "        [ 1.0794e+00, -5.3047e+00],\n",
       "        [-2.9206e+00, -9.0467e-01],\n",
       "        [ 5.0794e+00,  8.2953e+00],\n",
       "        [ 1.1079e+01, -1.0047e+00],\n",
       "        [-9.2056e-01, -1.1047e+00],\n",
       "        [-2.9206e+00, -5.1047e+00],\n",
       "        [-5.9206e+00, -3.0047e+00],\n",
       "        [ 3.0794e+00, -1.7047e+00],\n",
       "        [-5.9206e+00, -6.8047e+00],\n",
       "        [-4.9206e+00, -6.0047e+00],\n",
       "        [-6.9206e+00,  4.9953e+00],\n",
       "        [ 8.0794e+00, -1.8047e+00],\n",
       "        [ 1.0794e+00, -2.3047e+00],\n",
       "        [-1.9206e+00, -1.3047e+00],\n",
       "        [-7.9206e+00, -2.3047e+00],\n",
       "        [-1.9206e+00, -3.5047e+00],\n",
       "        [-1.1921e+01, -4.3047e+00],\n",
       "        [-1.0921e+01, -3.1047e+00],\n",
       "        [ 3.0794e+00, -7.0467e-01],\n",
       "        [-1.1921e+01,  1.9533e-01],\n",
       "        [-5.9206e+00, -6.0047e+00],\n",
       "        [-9.2056e-01,  4.3953e+00],\n",
       "        [-3.9206e+00,  3.3953e+00],\n",
       "        [ 1.0794e+00, -4.2047e+00],\n",
       "        [ 5.0794e+00,  1.1953e+00],\n",
       "        [-7.9206e+00, -7.6047e+00],\n",
       "        [-7.9206e+00, -5.4047e+00],\n",
       "        [-1.1921e+01, -1.5047e+00],\n",
       "        [-1.0921e+01, -3.9047e+00],\n",
       "        [ 4.0794e+00,  2.0953e+00],\n",
       "        [-9.9206e+00, -5.5047e+00],\n",
       "        [-2.9206e+00, -3.7047e+00],\n",
       "        [-4.9206e+00, -5.3047e+00],\n",
       "        [ 1.0794e+00, -5.2047e+00],\n",
       "        [-3.9206e+00, -3.4047e+00],\n",
       "        [-4.9206e+00, -1.5047e+00],\n",
       "        [-1.9206e+00, -6.1047e+00],\n",
       "        [ 5.0794e+00,  1.0953e+00],\n",
       "        [ 2.0794e+00,  3.5953e+00],\n",
       "        [ 6.0794e+00,  9.2953e+00],\n",
       "        [ 3.0794e+00,  7.9533e-01],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [ 1.1079e+01,  8.9953e+00],\n",
       "        [-1.9206e+00, -9.0467e-01],\n",
       "        [-2.9206e+00, -6.1047e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Your task is to again complete this class for the perceptron, with two changes from last time:\n",
    "- the implementation should use PyTorch tensors, not NumPy arrays;\n",
    "- `train_step` now accepts the entire dataset as input and should calculate the average gradient over all examples, rather than updating the weights one data point at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,lr=1e-3):\n",
    "        # store the learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # initialize the weights to small, normally-distributed values\n",
    "        self.w = torch.normal(mean=0, std=0.01, size=(2,))\n",
    "\n",
    "        # initialize the bias to zero\n",
    "        self.b = torch.zeros(1)\n",
    "\n",
    "    def train_step(self,X:torch.Tensor,y:torch.Tensor) -> None:\n",
    "        \"\"\" Apply the first update rule shown in lecture.\n",
    "            Arguments:\n",
    "             x: data matrix of shape (N,3)\n",
    "             y: labels of shape (N,) \n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        z = torch.matmul(X,self.w) + self.b\n",
    "        error = (y - z)\n",
    "        self.w += self.lr * torch.mean(error[:, None] * X, dim=0)  \n",
    "        self.b += self.lr * torch.mean(error)                     \n",
    "    \n",
    "    def predict(self,X:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model prediction for all data points.\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "            Returns:\n",
    "             Predicted labels (-1 or 1) of shape (N,)\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        z = torch.matmul(X, self.w) + self.b\n",
    "        return torch.where(z > 0, torch.tensor(1), torch.tensor(-1))\n",
    "    \n",
    "    def score(self,X:torch.Tensor,y:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model accuracy\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "             y: labels of shape (N,)\n",
    "            Returns:\n",
    "             Accuracy score\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        pred = self.predict(X)\n",
    "        return torch.mean((pred == y).float()).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to train the model and print out the accuracy at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 0.8177570104598999\n",
      "step 1: 0.827102780342102\n",
      "step 2: 0.8317757248878479\n",
      "step 3: 0.836448609828949\n",
      "step 4: 0.836448609828949\n",
      "step 5: 0.836448609828949\n",
      "step 6: 0.836448609828949\n",
      "step 7: 0.84112149477005\n",
      "step 8: 0.84112149477005\n",
      "step 9: 0.84112149477005\n",
      "step 10: 0.84112149477005\n",
      "step 11: 0.8457943797111511\n",
      "step 12: 0.8504672646522522\n",
      "step 13: 0.8504672646522522\n",
      "step 14: 0.8504672646522522\n",
      "step 15: 0.855140209197998\n",
      "step 16: 0.855140209197998\n",
      "step 17: 0.855140209197998\n",
      "step 18: 0.855140209197998\n",
      "step 19: 0.855140209197998\n",
      "step 20: 0.855140209197998\n",
      "step 21: 0.855140209197998\n",
      "step 22: 0.855140209197998\n",
      "step 23: 0.855140209197998\n",
      "step 24: 0.855140209197998\n",
      "step 25: 0.855140209197998\n",
      "step 26: 0.8598130941390991\n",
      "step 27: 0.8598130941390991\n",
      "step 28: 0.8644859790802002\n",
      "step 29: 0.8644859790802002\n",
      "step 30: 0.8644859790802002\n",
      "step 31: 0.8644859790802002\n",
      "step 32: 0.8691588640213013\n",
      "step 33: 0.8691588640213013\n",
      "step 34: 0.8691588640213013\n",
      "step 35: 0.8738317489624023\n",
      "step 36: 0.8785046935081482\n",
      "step 37: 0.8831775784492493\n",
      "step 38: 0.8831775784492493\n",
      "step 39: 0.8831775784492493\n",
      "step 40: 0.8831775784492493\n",
      "step 41: 0.8831775784492493\n",
      "step 42: 0.8831775784492493\n",
      "step 43: 0.8831775784492493\n",
      "step 44: 0.8831775784492493\n",
      "step 45: 0.8831775784492493\n",
      "step 46: 0.8831775784492493\n",
      "step 47: 0.8831775784492493\n",
      "step 48: 0.8831775784492493\n",
      "step 49: 0.8831775784492493\n",
      "step 50: 0.8831775784492493\n",
      "step 51: 0.8785046935081482\n",
      "step 52: 0.8785046935081482\n",
      "step 53: 0.8785046935081482\n",
      "step 54: 0.8785046935081482\n",
      "step 55: 0.8785046935081482\n",
      "step 56: 0.8785046935081482\n",
      "step 57: 0.8831775784492493\n",
      "step 58: 0.8831775784492493\n",
      "step 59: 0.8831775784492493\n",
      "step 60: 0.8831775784492493\n",
      "step 61: 0.8831775784492493\n",
      "step 62: 0.8831775784492493\n",
      "step 63: 0.8878504633903503\n",
      "step 64: 0.8925233483314514\n",
      "step 65: 0.8971962332725525\n",
      "step 66: 0.9018691778182983\n",
      "step 67: 0.9018691778182983\n",
      "step 68: 0.9018691778182983\n",
      "step 69: 0.9065420627593994\n",
      "step 70: 0.9065420627593994\n",
      "step 71: 0.9065420627593994\n",
      "step 72: 0.9158878326416016\n",
      "step 73: 0.9158878326416016\n",
      "step 74: 0.9158878326416016\n",
      "step 75: 0.9158878326416016\n",
      "step 76: 0.9158878326416016\n",
      "step 77: 0.9158878326416016\n",
      "step 78: 0.9158878326416016\n",
      "step 79: 0.9205607771873474\n",
      "step 80: 0.9205607771873474\n",
      "step 81: 0.9205607771873474\n",
      "step 82: 0.9205607771873474\n",
      "step 83: 0.9205607771873474\n",
      "step 84: 0.9205607771873474\n",
      "step 85: 0.9252336621284485\n",
      "step 86: 0.9252336621284485\n",
      "step 87: 0.9252336621284485\n",
      "step 88: 0.9252336621284485\n",
      "step 89: 0.9252336621284485\n",
      "step 90: 0.9252336621284485\n",
      "step 91: 0.9252336621284485\n",
      "step 92: 0.9252336621284485\n",
      "step 93: 0.9299065470695496\n",
      "step 94: 0.9299065470695496\n",
      "step 95: 0.9345794320106506\n",
      "step 96: 0.9345794320106506\n",
      "step 97: 0.9345794320106506\n",
      "step 98: 0.9345794320106506\n",
      "step 99: 0.9345794320106506\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "model = Perceptron(lr)\n",
    "for i in range(epochs):\n",
    "    model.train_step(X,y)\n",
    "    print(f'step {i}: {model.score(X,y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training multiple times.  Is the training the same each time, or does it vary?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the learning rate and number of epochs to find the best setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
